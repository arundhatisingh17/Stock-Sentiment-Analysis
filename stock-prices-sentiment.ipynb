{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5695469,"sourceType":"datasetVersion","datasetId":3270678},{"sourceId":11976357,"sourceType":"datasetVersion","datasetId":7249300}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Project Outline:\n\n- start off by deriving the monthly aggregated social media sentiment.\n- Use semantic methods on the tweets to determine the major sentiment associated with each event     and plot it out for better visual understanding.\n- Categorize the events into different domains - political, entertainment, etc.\n- use the most suitable correlation method to analayze the strength of the correlation between - -- Google's stock prices and the monthly aggregated sentiments. (Should be grouped my month for       uniformity)\n- find out which event specifically had the strongest correlation with google's stock price.\n- use all this data to predict google's future stocks using time-series anlaysis.","metadata":{}},{"cell_type":"code","source":"!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:56:50.205139Z","iopub.execute_input":"2025-05-28T21:56:50.205734Z","iopub.status.idle":"2025-05-28T21:56:55.486465Z","shell.execute_reply.started":"2025-05-28T21:56:50.205711Z","shell.execute_reply":"2025-05-28T21:56:55.485634Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# import statements\n\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport tqdm\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:56:57.379350Z","iopub.execute_input":"2025-05-28T21:56:57.380109Z","iopub.status.idle":"2025-05-28T21:56:57.384484Z","shell.execute_reply.started":"2025-05-28T21:56:57.380080Z","shell.execute_reply":"2025-05-28T21:56:57.383567Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"google_dataset = pd.read_csv(\"/kaggle/input/google-daily-stock-prices-2004-today/googl_daily_prices.csv\")\ntwitter_dataset = pd.read_csv(\"/kaggle/input/twitter-dataset/twitter_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:57:00.463504Z","iopub.execute_input":"2025-05-28T21:57:00.464319Z","iopub.status.idle":"2025-05-28T21:57:00.580541Z","shell.execute_reply.started":"2025-05-28T21:57:00.464293Z","shell.execute_reply":"2025-05-28T21:57:00.579581Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# conduct eda on the twitter dataset to understand it better\ntwitter_dataset.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T19:09:27.563454Z","iopub.execute_input":"2025-05-28T19:09:27.563913Z","iopub.status.idle":"2025-05-28T19:09:27.576097Z","shell.execute_reply.started":"2025-05-28T19:09:27.563858Z","shell.execute_reply":"2025-05-28T19:09:27.574722Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['Tweet_ID', 'Username', 'Text', 'Retweets', 'Likes', 'Timestamp'], dtype='object')"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# conduct sentiment anlaysis using TextBlob on the following tweets\n\ntwitter_dataset[\"Text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T19:09:29.121543Z","iopub.execute_input":"2025-05-28T19:09:29.121872Z","iopub.status.idle":"2025-05-28T19:09:29.138868Z","shell.execute_reply.started":"2025-05-28T19:09:29.121846Z","shell.execute_reply":"2025-05-28T19:09:29.137837Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0       Party least receive say or single. Prevent pre...\n1       Hotel still Congress may member staff. Media d...\n2       Nice be her debate industry that year. Film wh...\n3       Laugh explain situation career occur serious. ...\n4       Involve sense former often approach government...\n                              ...                        \n9995    Agree reflect military box ability ever hold. ...\n9996    Born which push still. Degree sometimes contro...\n9997    You day agent likely region. Teacher data mess...\n9998    Guess without successful save. Particular natu...\n9999    Body onto understand team about product beauti...\nName: Text, Length: 10000, dtype: object"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from textblob import TextBlob\n\n# create two columns for polarity and subjectivity\n\nfor id, row in twitter_dataset.iterrows():\n    tweet = row[\"Text\"]\n    sentiment = TextBlob(tweet).sentiment\n    polarity = sentiment.polarity\n    subjectivity = sentiment.subjectivity\n    twitter_dataset.loc[id, \"polarity\"] = polarity\n    twitter_dataset.loc[id, \"subjectivity\"] = subjectivity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T19:10:31.183132Z","iopub.execute_input":"2025-05-28T19:10:31.183640Z","iopub.status.idle":"2025-05-28T19:10:39.435396Z","shell.execute_reply.started":"2025-05-28T19:10:31.183603Z","shell.execute_reply":"2025-05-28T19:10:39.434420Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"twitter_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T19:10:42.261141Z","iopub.execute_input":"2025-05-28T19:10:42.262159Z","iopub.status.idle":"2025-05-28T19:10:42.292410Z","shell.execute_reply.started":"2025-05-28T19:10:42.262125Z","shell.execute_reply":"2025-05-28T19:10:42.290993Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      Tweet_ID         Username  \\\n0            1          julie81   \n1            2    richardhester   \n2            3   williamsjoseph   \n3            4      danielsmary   \n4            5       carlwarren   \n...        ...              ...   \n9995      9996            ntate   \n9996      9997   garrisonjoshua   \n9997      9998  adriennejackson   \n9998      9999         kcarlson   \n9999     10000       vdickerson   \n\n                                                   Text  Retweets  Likes  \\\n0     Party least receive say or single. Prevent pre...         2     25   \n1     Hotel still Congress may member staff. Media d...        35     29   \n2     Nice be her debate industry that year. Film wh...        51     25   \n3     Laugh explain situation career occur serious. ...        37     18   \n4     Involve sense former often approach government...        27     80   \n...                                                 ...       ...    ...   \n9995  Agree reflect military box ability ever hold. ...        81     86   \n9996  Born which push still. Degree sometimes contro...        73    100   \n9997  You day agent likely region. Teacher data mess...        10     62   \n9998  Guess without successful save. Particular natu...        21     60   \n9999  Body onto understand team about product beauti...        65     54   \n\n                Timestamp  polarity  subjectivity  \n0     2023-01-30 11:00:51  0.115714      0.552857  \n1     2023-01-02 22:45:58  0.308333      0.558333  \n2     2023-01-18 11:25:19  0.220000      0.600000  \n3     2023-04-10 22:06:29  0.054762      0.428571  \n4     2023-01-24 07:12:21  0.033333      0.133333  \n...                   ...       ...           ...  \n9995  2023-01-15 11:46:20 -0.150000      0.550000  \n9996  2023-05-06 00:46:54  0.046667      0.586667  \n9997  2023-02-27 14:55:08 -0.090476      0.378571  \n9998  2023-01-09 16:09:35  0.253770      0.506944  \n9999  2023-04-19 01:35:56  0.251667      0.488333  \n\n[10000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet_ID</th>\n      <th>Username</th>\n      <th>Text</th>\n      <th>Retweets</th>\n      <th>Likes</th>\n      <th>Timestamp</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>julie81</td>\n      <td>Party least receive say or single. Prevent pre...</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2023-01-30 11:00:51</td>\n      <td>0.115714</td>\n      <td>0.552857</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>richardhester</td>\n      <td>Hotel still Congress may member staff. Media d...</td>\n      <td>35</td>\n      <td>29</td>\n      <td>2023-01-02 22:45:58</td>\n      <td>0.308333</td>\n      <td>0.558333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>williamsjoseph</td>\n      <td>Nice be her debate industry that year. Film wh...</td>\n      <td>51</td>\n      <td>25</td>\n      <td>2023-01-18 11:25:19</td>\n      <td>0.220000</td>\n      <td>0.600000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>danielsmary</td>\n      <td>Laugh explain situation career occur serious. ...</td>\n      <td>37</td>\n      <td>18</td>\n      <td>2023-04-10 22:06:29</td>\n      <td>0.054762</td>\n      <td>0.428571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>carlwarren</td>\n      <td>Involve sense former often approach government...</td>\n      <td>27</td>\n      <td>80</td>\n      <td>2023-01-24 07:12:21</td>\n      <td>0.033333</td>\n      <td>0.133333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9996</td>\n      <td>ntate</td>\n      <td>Agree reflect military box ability ever hold. ...</td>\n      <td>81</td>\n      <td>86</td>\n      <td>2023-01-15 11:46:20</td>\n      <td>-0.150000</td>\n      <td>0.550000</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9997</td>\n      <td>garrisonjoshua</td>\n      <td>Born which push still. Degree sometimes contro...</td>\n      <td>73</td>\n      <td>100</td>\n      <td>2023-05-06 00:46:54</td>\n      <td>0.046667</td>\n      <td>0.586667</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9998</td>\n      <td>adriennejackson</td>\n      <td>You day agent likely region. Teacher data mess...</td>\n      <td>10</td>\n      <td>62</td>\n      <td>2023-02-27 14:55:08</td>\n      <td>-0.090476</td>\n      <td>0.378571</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9999</td>\n      <td>kcarlson</td>\n      <td>Guess without successful save. Particular natu...</td>\n      <td>21</td>\n      <td>60</td>\n      <td>2023-01-09 16:09:35</td>\n      <td>0.253770</td>\n      <td>0.506944</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>10000</td>\n      <td>vdickerson</td>\n      <td>Body onto understand team about product beauti...</td>\n      <td>65</td>\n      <td>54</td>\n      <td>2023-04-19 01:35:56</td>\n      <td>0.251667</td>\n      <td>0.488333</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# cell for committing work to github\n\n# !git clone https://huggingface.co/boltuix/bert-emotion\n\nsentiment_model = pipeline(\"text-classification\", model=\"boltuix/bert-emotion\")\ntwitter_dataset[\"sentiment\"] = twitter_dataset[\"Text\"].apply(lambda tweet: sentiment_model(tweet)[0][\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:57:07.092878Z","iopub.execute_input":"2025-05-28T21:57:07.093226Z","iopub.status.idle":"2025-05-28T21:57:52.590633Z","shell.execute_reply.started":"2025-05-28T21:57:07.093169Z","shell.execute_reply":"2025-05-28T21:57:52.589715Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2140dae9ab424f229322afede06302b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f517606ef5654e5785711a91ba0dfe5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77f2f409acd04e2eb6e4ac07a4037915"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/262k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a33e75633444a2a80d6bcf82e77d054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d5c47abf384c5bb4353baa1b271ece"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# write the twitter dataset into a csv file because it takes a while to load the dataset\n\ntwitter_dataset.to_csv(\"twitter_dataset.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:57:55.706280Z","iopub.execute_input":"2025-05-28T21:57:55.706837Z","iopub.status.idle":"2025-05-28T21:57:55.812848Z","shell.execute_reply.started":"2025-05-28T21:57:55.706809Z","shell.execute_reply":"2025-05-28T21:57:55.812105Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"twitter_dataset = pd.read_csv(\"/kaggle/working/twitter_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:57:57.742715Z","iopub.execute_input":"2025-05-28T21:57:57.743072Z","iopub.status.idle":"2025-05-28T21:57:57.787924Z","shell.execute_reply.started":"2025-05-28T21:57:57.743046Z","shell.execute_reply":"2025-05-28T21:57:57.787256Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"twitter_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:58:00.207749Z","iopub.execute_input":"2025-05-28T21:58:00.208052Z","iopub.status.idle":"2025-05-28T21:58:00.235442Z","shell.execute_reply.started":"2025-05-28T21:58:00.208030Z","shell.execute_reply":"2025-05-28T21:58:00.234727Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"      Tweet_ID         Username  \\\n0            1          julie81   \n1            2    richardhester   \n2            3   williamsjoseph   \n3            4      danielsmary   \n4            5       carlwarren   \n...        ...              ...   \n9995      9996            ntate   \n9996      9997   garrisonjoshua   \n9997      9998  adriennejackson   \n9998      9999         kcarlson   \n9999     10000       vdickerson   \n\n                                                   Text  Retweets  Likes  \\\n0     Party least receive say or single. Prevent pre...         2     25   \n1     Hotel still Congress may member staff. Media d...        35     29   \n2     Nice be her debate industry that year. Film wh...        51     25   \n3     Laugh explain situation career occur serious. ...        37     18   \n4     Involve sense former often approach government...        27     80   \n...                                                 ...       ...    ...   \n9995  Agree reflect military box ability ever hold. ...        81     86   \n9996  Born which push still. Degree sometimes contro...        73    100   \n9997  You day agent likely region. Teacher data mess...        10     62   \n9998  Guess without successful save. Particular natu...        21     60   \n9999  Body onto understand team about product beauti...        65     54   \n\n                Timestamp  sentiment  \n0     2023-01-30 11:00:51    neutral  \n1     2023-01-02 22:45:58    neutral  \n2     2023-01-18 11:25:19       love  \n3     2023-04-10 22:06:29    neutral  \n4     2023-01-24 07:12:21    neutral  \n...                   ...        ...  \n9995  2023-01-15 11:46:20  happiness  \n9996  2023-05-06 00:46:54    neutral  \n9997  2023-02-27 14:55:08    neutral  \n9998  2023-01-09 16:09:35  happiness  \n9999  2023-04-19 01:35:56  happiness  \n\n[10000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet_ID</th>\n      <th>Username</th>\n      <th>Text</th>\n      <th>Retweets</th>\n      <th>Likes</th>\n      <th>Timestamp</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>julie81</td>\n      <td>Party least receive say or single. Prevent pre...</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2023-01-30 11:00:51</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>richardhester</td>\n      <td>Hotel still Congress may member staff. Media d...</td>\n      <td>35</td>\n      <td>29</td>\n      <td>2023-01-02 22:45:58</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>williamsjoseph</td>\n      <td>Nice be her debate industry that year. Film wh...</td>\n      <td>51</td>\n      <td>25</td>\n      <td>2023-01-18 11:25:19</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>danielsmary</td>\n      <td>Laugh explain situation career occur serious. ...</td>\n      <td>37</td>\n      <td>18</td>\n      <td>2023-04-10 22:06:29</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>carlwarren</td>\n      <td>Involve sense former often approach government...</td>\n      <td>27</td>\n      <td>80</td>\n      <td>2023-01-24 07:12:21</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9996</td>\n      <td>ntate</td>\n      <td>Agree reflect military box ability ever hold. ...</td>\n      <td>81</td>\n      <td>86</td>\n      <td>2023-01-15 11:46:20</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9997</td>\n      <td>garrisonjoshua</td>\n      <td>Born which push still. Degree sometimes contro...</td>\n      <td>73</td>\n      <td>100</td>\n      <td>2023-05-06 00:46:54</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9998</td>\n      <td>adriennejackson</td>\n      <td>You day agent likely region. Teacher data mess...</td>\n      <td>10</td>\n      <td>62</td>\n      <td>2023-02-27 14:55:08</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9999</td>\n      <td>kcarlson</td>\n      <td>Guess without successful save. Particular natu...</td>\n      <td>21</td>\n      <td>60</td>\n      <td>2023-01-09 16:09:35</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>10000</td>\n      <td>vdickerson</td>\n      <td>Body onto understand team about product beauti...</td>\n      <td>65</td>\n      <td>54</td>\n      <td>2023-04-19 01:35:56</td>\n      <td>happiness</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\n\nprint(torch.cuda.is_available())  # Should return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:58:07.429608Z","iopub.execute_input":"2025-05-28T21:58:07.429921Z","iopub.status.idle":"2025-05-28T21:58:07.434336Z","shell.execute_reply.started":"2025-05-28T21:58:07.429898Z","shell.execute_reply":"2025-05-28T21:58:07.433369Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# categorize these tweets into different domains; add a domains column to the dataset\nfrom transformers import pipeline\ntqdm.pandas()\n\nclassifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)\ncandidate_labels = [\"sports\", \"politics\", \"technology\", \"finance\", \"entertainment\", \"health\", \"education\"]\n\ntwitter_dataset[\"domain\"] = twitter_dataset[\"Text\"].progress_apply(lambda x: classifier(x, candidate_labels)[\"labels\"][0])\n  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:58:09.602008Z","iopub.execute_input":"2025-05-28T21:58:09.602426Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73aec93268e14b87a1fa94bf55fe27f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aabab91c89ed4605b72c488851d79c1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b2af5f9b5dd423c8d19ffb4d719a4c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14fb3884dc64bb98eb14130a5544751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6138bcf08f4a0f9ca793cfb9849b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00734d8fc858448da0bfdeaf52911635"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b18da2128216471a997e2aadd3c34207"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"twitter_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T23:09:38.317976Z","iopub.execute_input":"2025-05-28T23:09:38.318304Z","iopub.status.idle":"2025-05-28T23:09:38.331426Z","shell.execute_reply.started":"2025-05-28T23:09:38.318276Z","shell.execute_reply":"2025-05-28T23:09:38.329896Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"      Tweet_ID         Username  \\\n0            1          julie81   \n1            2    richardhester   \n2            3   williamsjoseph   \n3            4      danielsmary   \n4            5       carlwarren   \n...        ...              ...   \n9995      9996            ntate   \n9996      9997   garrisonjoshua   \n9997      9998  adriennejackson   \n9998      9999         kcarlson   \n9999     10000       vdickerson   \n\n                                                   Text  Retweets  Likes  \\\n0     Party least receive say or single. Prevent pre...         2     25   \n1     Hotel still Congress may member staff. Media d...        35     29   \n2     Nice be her debate industry that year. Film wh...        51     25   \n3     Laugh explain situation career occur serious. ...        37     18   \n4     Involve sense former often approach government...        27     80   \n...                                                 ...       ...    ...   \n9995  Agree reflect military box ability ever hold. ...        81     86   \n9996  Born which push still. Degree sometimes contro...        73    100   \n9997  You day agent likely region. Teacher data mess...        10     62   \n9998  Guess without successful save. Particular natu...        21     60   \n9999  Body onto understand team about product beauti...        65     54   \n\n                Timestamp  sentiment         domain  \n0     2023-01-30 11:00:51    neutral  entertainment  \n1     2023-01-02 22:45:58    neutral  entertainment  \n2     2023-01-18 11:25:19       love  entertainment  \n3     2023-04-10 22:06:29    neutral  entertainment  \n4     2023-01-24 07:12:21    neutral       politics  \n...                   ...        ...            ...  \n9995  2023-01-15 11:46:20  happiness         sports  \n9996  2023-05-06 00:46:54    neutral      education  \n9997  2023-02-27 14:55:08    neutral      education  \n9998  2023-01-09 16:09:35  happiness  entertainment  \n9999  2023-04-19 01:35:56  happiness  entertainment  \n\n[10000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet_ID</th>\n      <th>Username</th>\n      <th>Text</th>\n      <th>Retweets</th>\n      <th>Likes</th>\n      <th>Timestamp</th>\n      <th>sentiment</th>\n      <th>domain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>julie81</td>\n      <td>Party least receive say or single. Prevent pre...</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2023-01-30 11:00:51</td>\n      <td>neutral</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>richardhester</td>\n      <td>Hotel still Congress may member staff. Media d...</td>\n      <td>35</td>\n      <td>29</td>\n      <td>2023-01-02 22:45:58</td>\n      <td>neutral</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>williamsjoseph</td>\n      <td>Nice be her debate industry that year. Film wh...</td>\n      <td>51</td>\n      <td>25</td>\n      <td>2023-01-18 11:25:19</td>\n      <td>love</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>danielsmary</td>\n      <td>Laugh explain situation career occur serious. ...</td>\n      <td>37</td>\n      <td>18</td>\n      <td>2023-04-10 22:06:29</td>\n      <td>neutral</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>carlwarren</td>\n      <td>Involve sense former often approach government...</td>\n      <td>27</td>\n      <td>80</td>\n      <td>2023-01-24 07:12:21</td>\n      <td>neutral</td>\n      <td>politics</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>9996</td>\n      <td>ntate</td>\n      <td>Agree reflect military box ability ever hold. ...</td>\n      <td>81</td>\n      <td>86</td>\n      <td>2023-01-15 11:46:20</td>\n      <td>happiness</td>\n      <td>sports</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9997</td>\n      <td>garrisonjoshua</td>\n      <td>Born which push still. Degree sometimes contro...</td>\n      <td>73</td>\n      <td>100</td>\n      <td>2023-05-06 00:46:54</td>\n      <td>neutral</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9998</td>\n      <td>adriennejackson</td>\n      <td>You day agent likely region. Teacher data mess...</td>\n      <td>10</td>\n      <td>62</td>\n      <td>2023-02-27 14:55:08</td>\n      <td>neutral</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9999</td>\n      <td>kcarlson</td>\n      <td>Guess without successful save. Particular natu...</td>\n      <td>21</td>\n      <td>60</td>\n      <td>2023-01-09 16:09:35</td>\n      <td>happiness</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>10000</td>\n      <td>vdickerson</td>\n      <td>Body onto understand team about product beauti...</td>\n      <td>65</td>\n      <td>54</td>\n      <td>2023-04-19 01:35:56</td>\n      <td>happiness</td>\n      <td>entertainment</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# write the twitter dataset into a csv file because it takes a while to load the dataset\n\ntwitter_dataset.to_csv(\"twitter_dataset(domain).csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T23:09:45.371800Z","iopub.execute_input":"2025-05-28T23:09:45.372098Z","iopub.status.idle":"2025-05-28T23:09:45.480768Z","shell.execute_reply.started":"2025-05-28T23:09:45.372074Z","shell.execute_reply":"2025-05-28T23:09:45.480091Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"twitter_dataset = pd.read_csv(\"/kaggle/working/twitter_dataset(domain).csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T23:09:48.496752Z","iopub.execute_input":"2025-05-28T23:09:48.497022Z","iopub.status.idle":"2025-05-28T23:09:48.540724Z","shell.execute_reply.started":"2025-05-28T23:09:48.497001Z","shell.execute_reply":"2025-05-28T23:09:48.540057Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# plot out the popularity of emotions for each of the domains","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# find the total number of retweets and likes for each of the domain","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# merge the twitter dataset and the google dataset after grouping by month and year in both the datasets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyze the correlation between Google stock prices and tweet emotions across different domains\n# to identify which domain's emotional activity most closely tracks market movements.","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}